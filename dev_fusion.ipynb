{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557fa872",
   "metadata": {},
   "source": [
    "## Pulling the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd93785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "REPO_NAME = \"FusionKAN\"\n",
    "# Tip: If private, use: https://<your_token>@github.com/yourname/FusionKAN.git\n",
    "REPO_URL = \"https://github.com/DonKamilo00/FusionKAN.git\" \n",
    "BRANCH = \"main\" \n",
    "\n",
    "# --- SETUP LOGIC ---\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    print(f\"üöÄ Cloning {REPO_NAME}...\")\n",
    "    !git clone {REPO_URL}\n",
    "    %cd {REPO_NAME}\n",
    "else:\n",
    "    print(f\"üîÑ Repo exists. Updating...\")\n",
    "    %cd {REPO_NAME}\n",
    "    !git fetch origin\n",
    "    !git reset --hard origin/{BRANCH} # Force overwrite local changes to match remote\n",
    "\n",
    "# --- INSTALL BUILD DEPENDENCIES ---\n",
    "# Ninja makes C++ compilation much faster\n",
    "!pip install ninja \n",
    "\n",
    "# --- COMPILE & INSTALL FUSIONKAN ---\n",
    "print(\"‚öôÔ∏è Compiling CUDA Kernels (this may take a moment)...\")\n",
    "# --no-deps: Don't waste time checking torch/numpy installation every time\n",
    "# --force-reinstall: Ensures the C++ extension is actually rebuilt\n",
    "!pip install . --verbose --no-deps --force-reinstall\n",
    "\n",
    "print(\"‚úÖ Setup Complete. FusionKAN is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316eca83",
   "metadata": {},
   "source": [
    "# Saving changes to the .Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8850e745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author identity unknown\n",
      "\n",
      "*** Please tell me who you are.\n",
      "\n",
      "Run\n",
      "\n",
      "  git config --global user.email \"you@example.com\"\n",
      "  git config --global user.name \"Your Name\"\n",
      "\n",
      "to set your account's default identity.\n",
      "Omit --global to set the identity only in this repository.\n",
      "\n",
      "fatal: unable to auto-detect email address (got 'root@a4fdbe0801af.(none)')\n",
      "fatal: could not read Username for 'https://github.com': No such device or address\n"
     ]
    }
   ],
   "source": [
    "!git add .\n",
    "!git commit -m \"update kernel\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80d1d8e",
   "metadata": {},
   "source": [
    "# Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4685d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/FusionKAN\n",
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (4/4), 841 bytes | 841.00 KiB/s, done.\n",
      "From https://github.com/DonKamilo00/FusionKAN\n",
      "   d878856..f1087f0  main       -> origin/main\n",
      "Updating d878856..f1087f0\n",
      "Fast-forward\n",
      " csrc/fusion_kan.cu | 112 \u001b[32m++++++++++++++++++++++\u001b[m\u001b[31m-------------------------------\u001b[m\n",
      " 1 file changed, 47 insertions(+), 65 deletions(-)\n",
      "Processing /content/FusionKAN\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: fusion_kan\n",
      "  Building wheel for fusion_kan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fusion_kan: filename=fusion_kan-1.0.0-cp312-cp312-linux_x86_64.whl size=119675 sha256=8d9ab1a8d48ec083177d073170962374da769bd4590558712ffc1d8069e19395\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-oftrljh9/wheels/ba/ee/1a/c6dba8d3add4302b13e8353459dd01ef403bc9ab63abe170dd\n",
      "Successfully built fusion_kan\n",
      "Installing collected packages: fusion_kan\n",
      "  Attempting uninstall: fusion_kan\n",
      "    Found existing installation: fusion_kan 1.0.0\n",
      "    Uninstalling fusion_kan-1.0.0:\n",
      "      Successfully uninstalled fusion_kan-1.0.0\n",
      "Successfully installed fusion_kan-1.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "9bf1848df2214ffe847ba7a38d2128c9",
       "pip_warning": {
        "packages": [
         "_fusion_kan_cuda",
         "fusion_kan"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Library Updated\n"
     ]
    }
   ],
   "source": [
    "# Run this cell whenever you push changes to GitHub\n",
    "%cd /content/FusionKAN\n",
    "!git pull\n",
    "!pip install . --no-deps --force-reinstall\n",
    "print(\"‚úÖ Library Updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec070487",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628185b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error: CUDA Backend not found. Did compilation fail?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3583575674.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFusionKANLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \"\"\"\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1082\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \"\"\"\n\u001b[0;32m-> 1084\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import fusion_kan\n",
    "from fusion_kan import FusionKANLayer\n",
    "\n",
    "# Verify the C++ backend loaded correctly\n",
    "try:\n",
    "    from fusion_kan.functional import _backend\n",
    "    print(\"CUDA Backend Loaded Successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Error: CUDA Backend not found. Did compilation fail?\")\n",
    "\n",
    "# --- Your Benchmark / Test Code Here ---\n",
    "batch_size = 4096\n",
    "in_features = 32\n",
    "out_features = 64\n",
    "\n",
    "layer = FusionKANLayer(in_features, out_features).cuda()\n",
    "x = torch.randn(batch_size, in_features).cuda()\n",
    "\n",
    "# Forward pass\n",
    "y = layer(x)\n",
    "print(f\"Forward pass output shape: {y.shape}\")\n",
    "\n",
    "# Backward pass (Critical for testing your new kernel gradients)\n",
    "loss = y.sum()\n",
    "loss.backward()\n",
    "print(\"Backward pass successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e4c0490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  7 13:20:09 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   62C    P0             32W /   72W |     267MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ef6cc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/FusionKAN\n",
      "Processing /content/FusionKAN\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: fusion_kan\n",
      "  Building wheel for fusion_kan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fusion_kan: filename=fusion_kan-1.0.0-cp312-cp312-linux_x86_64.whl size=119675 sha256=b9442d3ce2e44181933f1e80408647a9a01c45079cbcac081c43b1035a82242d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ex67f069/wheels/ba/ee/1a/c6dba8d3add4302b13e8353459dd01ef403bc9ab63abe170dd\n",
      "Successfully built fusion_kan\n",
      "Installing collected packages: fusion_kan\n",
      "  Attempting uninstall: fusion_kan\n",
      "    Found existing installation: fusion_kan 1.0.0\n",
      "    Uninstalling fusion_kan-1.0.0:\n",
      "      Successfully uninstalled fusion_kan-1.0.0\n",
      "Successfully installed fusion_kan-1.0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "2cf0d76b07754fa1bdf8f57e1a0ef929",
       "pip_warning": {
        "packages": [
         "_fusion_kan_cuda",
         "fusion_kan"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this in a Jupyter Cell to recompile\n",
    "%cd /content/FusionKAN\n",
    "!pip install . --no-deps --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ce343d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionKAN Version: 1.0.0\n",
      "CUDA Available: True\n",
      "\n",
      "--- 1. NUMERICAL CORRECTNESS (GradCheck) ---\n",
      "Running torch.autograd.gradcheck...\n",
      "‚ùå Gradient Check FAILED\n",
      "Jacobian mismatch for output 0 with respect to input 2,\n",
      "numerical:tensor([[ 3.5091e+00, -6.2894e-02,  1.5061e+00, -7.9844e-03,  1.4906e+00,\n",
      "         -4.4650e-01,  1.0797e+00, -5.4398e-01,  3.2259e+00, -2.7854e-01,\n",
      "          1.7888e+00, -1.2435e+00,  1.5045e+00,  3.4104e-01, -1.7525e-01,\n",
      "          9.4578e-01,  3.1987e+00, -1.6599e+00,  2.0668e+00,  6.2391e-01,\n",
      "          1.3972e+00,  7.5625e-01,  1.5156e-03, -2.5742e+00, -1.1103e+00,\n",
      "         -9.3917e-02, -2.8047e-01,  6.4728e-01,  5.4296e-01,  5.0253e-01,\n",
      "         -1.4386e+00,  1.1189e+00]], device='cuda:0', dtype=torch.float64)\n",
      "analytical:tensor([[ 1.0527e+01, -1.8871e-01,  4.5184e+00, -2.3943e-02,  4.4718e+00,\n",
      "         -1.3395e+00,  3.2390e+00, -1.6320e+00,  9.6777e+00, -8.3565e-01,\n",
      "          5.3665e+00, -3.7306e+00,  4.5136e+00,  1.0231e+00, -5.2573e-01,\n",
      "          2.8373e+00,  9.5961e+00, -4.9797e+00,  6.2004e+00,  1.8717e+00,\n",
      "          4.1915e+00,  2.2687e+00,  4.5469e-03, -7.7226e+00, -3.3309e+00,\n",
      "         -2.8175e-01, -8.4140e-01,  1.9418e+00,  1.6289e+00,  1.5075e+00,\n",
      "         -4.3158e+00,  3.3568e+00]], device='cuda:0', dtype=torch.float64)\n",
      "\n",
      "\n",
      "--- 2. PERFORMANCE STRESS TEST (Shared Memory Tiling) ---\n",
      "Config: Batch=16384, In=32, Out=64, Grid=100\n",
      "‚úÖ Stress Test Complete.\n",
      "Avg Time (Forward+Backward): 4.53 ms per step\n",
      "Throughput: 3,615,290 samples/sec\n",
      "\n",
      "--- 3. SANITY CHECK (Training Loop) ---\n",
      "Training 50 steps...\n",
      "Step 0: Loss 0.366399\n",
      "Step 10: Loss 0.191008\n",
      "Step 20: Loss 0.070304\n",
      "Step 30: Loss 0.018606\n",
      "Step 40: Loss 0.007816\n",
      "‚úÖ Convergence Check PASSED (Loss < 0.1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import gradcheck\n",
    "import time\n",
    "import importlib\n",
    "import fusion_kan\n",
    "importlib.reload(fusion_kan) # Force reload of the module\n",
    "from fusion_kan.functional import FusionKANFunction\n",
    "from fusion_kan.layer import FusionKANLayer\n",
    "\n",
    "print(f\"FusionKAN Version: {fusion_kan.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "def run_gradient_check():\n",
    "    print(\"\\n--- 1. NUMERICAL CORRECTNESS (GradCheck) ---\")\n",
    "    # gradcheck requires double precision (float64) for numerical stability\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    # Small dimensions for valid numerical check\n",
    "    B, In, Out = 4, 4, 8\n",
    "    grid_size = 5\n",
    "    \n",
    "    # Inputs\n",
    "    inputs = torch.randn(B, In, dtype=torch.float64, device=device, requires_grad=True)\n",
    "    weights = torch.randn(Out, In, grid_size + 3, dtype=torch.float64, device=device, requires_grad=True)\n",
    "    \n",
    "    # Grid bounds (scalar tensors)\n",
    "    grid_min = torch.tensor(-1.0, dtype=torch.float64, device=device, requires_grad=True)\n",
    "    grid_max = torch.tensor(1.0, dtype=torch.float64, device=device, requires_grad=True)\n",
    "    \n",
    "    print(\"Running torch.autograd.gradcheck...\")\n",
    "    try:\n",
    "        # We test the custom Function directly\n",
    "        test = gradcheck(\n",
    "            FusionKANFunction.apply, \n",
    "            (inputs, weights, grid_size, grid_min, grid_max), \n",
    "            eps=1e-6, \n",
    "            atol=1e-4\n",
    "        )\n",
    "        print(f\"‚úÖ Gradient Check PASSED: {test}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Gradient Check FAILED\")\n",
    "        print(e)\n",
    "\n",
    "def run_stress_test():\n",
    "    print(\"\\n--- 2. PERFORMANCE STRESS TEST (Shared Memory Tiling) ---\")\n",
    "    # This tests if the Block/Grid logic holds up under heavy load\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    # Large dimensions typical for 3D/NeRF\n",
    "    B = 16384     # Large Batch\n",
    "    In = 32       # Typical Coordinate Encoding width\n",
    "    Out = 64      # Typical Hidden width\n",
    "    grid_size = 100 # High resolution grid\n",
    "    \n",
    "    print(f\"Config: Batch={B}, In={In}, Out={Out}, Grid={grid_size}\")\n",
    "    \n",
    "    layer = FusionKANLayer(In, Out, grid_size=grid_size).to(device)\n",
    "    x = torch.randn(B, In, device=device)\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(10):\n",
    "        y = layer(x)\n",
    "        loss = y.sum()\n",
    "        loss.backward()\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    \n",
    "    steps = 100\n",
    "    for _ in range(steps):\n",
    "        # Forward\n",
    "        y = layer(x)\n",
    "        # Backward\n",
    "        loss = y.sum()\n",
    "        loss.backward()\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_time = (end - start) / steps * 1000 # ms\n",
    "    print(f\"‚úÖ Stress Test Complete.\")\n",
    "    print(f\"Avg Time (Forward+Backward): {avg_time:.2f} ms per step\")\n",
    "    print(f\"Throughput: {B * steps / (end - start):,.0f} samples/sec\")\n",
    "\n",
    "def run_convergence_test():\n",
    "    print(\"\\n--- 3. SANITY CHECK (Training Loop) ---\")\n",
    "    # Simple task: Learn Identity function y = x\n",
    "    # If gradients are wrong, loss will explode or stay flat.\n",
    "    \n",
    "    model = FusionKANLayer(1, 1, grid_size=10).cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Data: y = sin(x)\n",
    "    x_train = torch.linspace(-2, 2, 1000).view(-1, 1).cuda()\n",
    "    y_train = torch.sin(x_train)\n",
    "    \n",
    "    print(\"Training 50 steps...\")\n",
    "    for i in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x_train)\n",
    "        loss = torch.nn.functional.mse_loss(pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Step {i}: Loss {loss.item():.6f}\")\n",
    "            \n",
    "    if loss.item() < 0.1:\n",
    "        print(\"‚úÖ Convergence Check PASSED (Loss < 0.1)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Convergence Check SUSPICIOUS (Loss is high)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_gradient_check()\n",
    "    run_stress_test()\n",
    "    run_convergence_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
